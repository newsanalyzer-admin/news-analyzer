# Story 2.2.1: Wikidata Property Extraction

## Status
Draft

## Story
**As a** system,
**I want to** fetch rich properties from Wikidata for linked entities,
**so that** entities are enriched with authoritative metadata from external sources.

## Acceptance Criteria
1. Fetch key properties for each entity type from Wikidata
2. Map Wikidata properties to Schema.org properties
3. Handle missing properties gracefully (return partial data)
4. Support property value types: string, date, URL, entity reference
5. Cache property data with 7-day TTL
6. Track property provenance (source: "wikidata")
7. Return structured property data ready for merge

## Tasks / Subtasks
- [ ] Create PropertyExtractor class (AC: 1, 2)
  - [ ] Define property mappings per entity type
  - [ ] Build SPARQL queries for property fetching
  - [ ] Parse SPARQL results into structured format
- [ ] Implement type-specific property fetching (AC: 1)
  - [ ] Person properties: birthDate, nationality, jobTitle, image
  - [ ] Organization properties: foundingDate, url, location, parentOrganization
  - [ ] Place properties: coordinates, country, population
- [ ] Implement Schema.org mapping (AC: 2)
  - [ ] Map Wikidata property IDs to Schema.org properties
  - [ ] Handle nested objects (e.g., location as Place)
  - [ ] Format values correctly (ISO dates, URLs)
- [ ] Handle property value types (AC: 4)
  - [ ] String literals
  - [ ] Date/time values
  - [ ] URLs
  - [ ] Entity references (resolve to labels)
- [ ] Implement caching (AC: 5)
  - [ ] Cache key: `props:{wikidata_id}`
  - [ ] 7-day TTL
  - [ ] Store full property set
- [ ] Add provenance tracking (AC: 6)
  - [ ] Tag each property with source
  - [ ] Include fetch timestamp
- [ ] Write unit tests
  - [ ] Test property fetching for each type
  - [ ] Test Schema.org mapping
  - [ ] Test missing property handling
  - [ ] Test caching behavior

## Dev Notes

### Relevant Source Tree
```
reasoning-service/
├── app/
│   ├── services/
│   │   ├── property_extractor.py  # NEW - Create this file
│   │   ├── wikidata_client.py     # Story 2.1.1 - reuse for SPARQL
│   │   └── entity_linker.py       # Story 2.1.4 - will call this
└── tests/
    └── test_property_extractor.py # NEW - Create this file
```

### Wikidata Property Mappings

#### Person (Q5)
| Wikidata Property | Property ID | Schema.org Property |
|-------------------|-------------|---------------------|
| Date of birth | P569 | birthDate |
| Place of birth | P19 | birthPlace |
| Date of death | P570 | deathDate |
| Citizenship | P27 | nationality |
| Occupation | P106 | jobTitle |
| Position held | P39 | hasOccupation |
| Member of political party | P102 | memberOf |
| Official website | P856 | url |
| Image | P18 | image |

#### Organization (Q43229)
| Wikidata Property | Property ID | Schema.org Property |
|-------------------|-------------|---------------------|
| Inception date | P571 | foundingDate |
| Dissolution date | P576 | dissolutionDate |
| Headquarters location | P159 | location |
| Official website | P856 | url |
| Parent organization | P749 | parentOrganization |
| Subsidiary | P355 | subOrganization |

#### Government Organization (Q327333)
| Wikidata Property | Property ID | Schema.org Property |
|-------------------|-------------|---------------------|
| Country | P17 | areaServed |
| Jurisdiction | P1001 | (custom) jurisdiction |
| Official name | P1448 | legalName |
| Head of organization | P35 | employee (head) |

#### Place (Q515/Q6256)
| Wikidata Property | Property ID | Schema.org Property |
|-------------------|-------------|---------------------|
| Coordinate location | P625 | geo (GeoCoordinates) |
| Country | P17 | containedInPlace |
| Population | P1082 | (custom) population |

### SPARQL Query Template

```sparql
SELECT ?prop ?propLabel ?value ?valueLabel WHERE {
  wd:Q217173 ?prop ?value .  # Q217173 = EPA

  # Filter to properties we care about
  VALUES ?prop {
    wdt:P571   # inception
    wdt:P576   # dissolution
    wdt:P159   # headquarters
    wdt:P856   # website
    wdt:P749   # parent org
    wdt:P17    # country
    wdt:P1001  # jurisdiction
  }

  SERVICE wikibase:label { bd:serviceParam wikibase:language "en". }
}
```

### Property Extractor Class

```python
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from datetime import datetime

@dataclass
class ExtractedProperty:
    schema_org_key: str
    value: Any
    value_type: str  # "string", "date", "url", "reference"
    source: str = "wikidata"
    fetched_at: datetime = None

class PropertyExtractor:
    # Property mappings per type
    PERSON_PROPERTIES = {
        "P569": "birthDate",
        "P570": "deathDate",
        "P27": "nationality",
        "P106": "jobTitle",
        "P39": "hasOccupation",
        "P102": "memberOf",
        "P856": "url",
        "P18": "image",
    }

    ORGANIZATION_PROPERTIES = {
        "P571": "foundingDate",
        "P576": "dissolutionDate",
        "P159": "location",
        "P856": "url",
        "P749": "parentOrganization",
        "P17": "areaServed",
    }

    def __init__(self, wikidata_client):
        self.wikidata = wikidata_client
        self.cache = TTLCache(maxsize=5000, ttl=604800)  # 7 days

    async def extract_properties(
        self,
        wikidata_id: str,
        entity_type: str
    ) -> Dict[str, ExtractedProperty]:
        # Check cache
        cache_key = f"props:{wikidata_id}"
        if cache_key in self.cache:
            return self.cache[cache_key]

        # Get property mapping for type
        prop_mapping = self._get_property_mapping(entity_type)

        # Build and execute SPARQL query
        query = self._build_property_query(wikidata_id, prop_mapping.keys())
        results = await self.wikidata.query_sparql(query)

        # Parse results
        properties = {}
        for row in results:
            prop_id = self._extract_property_id(row["prop"])
            if prop_id in prop_mapping:
                schema_key = prop_mapping[prop_id]
                value, value_type = self._parse_value(row["value"], row.get("valueLabel"))

                properties[schema_key] = ExtractedProperty(
                    schema_org_key=schema_key,
                    value=value,
                    value_type=value_type,
                    source="wikidata",
                    fetched_at=datetime.utcnow()
                )

        # Cache and return
        self.cache[cache_key] = properties
        return properties

    def _get_property_mapping(self, entity_type: str) -> Dict[str, str]:
        mappings = {
            "person": self.PERSON_PROPERTIES,
            "government_org": self.ORGANIZATION_PROPERTIES,
            "organization": self.ORGANIZATION_PROPERTIES,
            "location": self.PLACE_PROPERTIES,
        }
        return mappings.get(entity_type, {})

    def _parse_value(self, value: str, label: Optional[str]) -> tuple:
        """Parse Wikidata value into typed Python value"""
        # Date detection
        if "T00:00:00Z" in value:
            return value.split("T")[0], "date"

        # URL detection
        if value.startswith("http"):
            return value, "url"

        # Entity reference (has Q-id)
        if value.startswith("http://www.wikidata.org/entity/Q"):
            return label or value, "reference"

        # Default to string
        return label or value, "string"
```

### Output Format

```python
{
    "foundingDate": ExtractedProperty(
        schema_org_key="foundingDate",
        value="1970-12-02",
        value_type="date",
        source="wikidata",
        fetched_at=datetime(2025, 11, 25, 10, 30, 0)
    ),
    "url": ExtractedProperty(
        schema_org_key="url",
        value="https://www.epa.gov",
        value_type="url",
        source="wikidata",
        fetched_at=datetime(2025, 11, 25, 10, 30, 0)
    ),
    "location": ExtractedProperty(
        schema_org_key="location",
        value="Washington, D.C.",
        value_type="reference",
        source="wikidata",
        fetched_at=datetime(2025, 11, 25, 10, 30, 0)
    )
}
```

## Testing

### Test File Location
`reasoning-service/tests/test_property_extractor.py`

### Testing Standards
- Use pytest framework with pytest-asyncio
- Mock Wikidata SPARQL responses
- Test each entity type
- Minimum 90% coverage

### Test Cases
```python
@pytest.mark.asyncio
async def test_extract_person_properties():
    """Test extracting properties for Person type"""

@pytest.mark.asyncio
async def test_extract_organization_properties():
    """Test extracting properties for Organization type"""

@pytest.mark.asyncio
async def test_schema_org_mapping():
    """Test Wikidata props mapped to Schema.org correctly"""

@pytest.mark.asyncio
async def test_date_parsing():
    """Test date values parsed to ISO format"""

@pytest.mark.asyncio
async def test_url_parsing():
    """Test URL values detected correctly"""

@pytest.mark.asyncio
async def test_entity_reference_resolved():
    """Test entity references use labels"""

@pytest.mark.asyncio
async def test_missing_properties_handled():
    """Test partial data returned when some props missing"""

@pytest.mark.asyncio
async def test_caching():
    """Test properties cached for 7 days"""

@pytest.mark.asyncio
async def test_provenance_tracking():
    """Test each property tagged with source"""
```

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-11-25 | 1.0 | Initial story creation | Sarah (PO) |

## Dev Agent Record

### Agent Model Used
_To be filled by dev agent_

### Debug Log References
_To be filled by dev agent_

### Completion Notes List
_To be filled by dev agent_

### File List
_To be filled by dev agent_

## QA Results
_To be filled by QA agent_
